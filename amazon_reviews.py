# -*- coding: utf-8 -*-
"""Amazon_Reviews.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jx3pgEL_Nt-kyjt-iMf1rW3nQnhPv4-Z
"""

import pandas as pd
# Upload the file in Google Colab
from google.colab import files
uploaded = files.upload()

# Try reading the CSV with a more robust engine and error handling
df = pd.read_csv("Amazon_Reviews.csv", engine='python', on_bad_lines='warn')

# Initial Data Check
df.shape
df.info()
df.isna().sum().sort_values(ascending=False)

df.head()

df.shape

df.info()

df.isnull().mean().sort_values(ascending=False)

df.duplicated().sum()

df = df.drop_duplicates()

df = df.dropna(subset=["Text;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;"])

import re
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
def clean_text(text):
 text = text.lower()
 text = re.sub(r"http\S+", "", text) # remove URLs
 text = re.sub(r"<.*?>", "", text) # remove HTML
 text = re.sub(r"[^a-z\s]", "", text) # remove punctuation and numbers
 text = text.split()
 text = [word for word in text if word not in stop_words]
 return " ".join(text)

df["Text;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;"] = df["Text;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;"].apply(clean_text)

df["Score"].value_counts().sort_index().plot(kind="bar")

df["rating_category"] = df["Score"].apply(
 lambda x: "Positive" if x >= 4 else "Neutral" if x == 3 else "Negative"
)
df["rating_category"].value_counts().plot(kind="bar")

df.groupby("ProductId")["Score"].mean().sort_values().head(10)

df["ProductId"].value_counts().head(10).plot(kind="bar")

df["review_length"] = df["Text;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;"].apply(len)
df.groupby("Score")["review_length"].mean().plot(kind="bar")

df["review_date"] = pd.to_datetime(df["Time"], unit='s')
df.set_index("review_date").resample("M").size().plot()

df[df["Score"] <= 2]["ProductId"].value_counts().head(10)

df["Score"].value_counts(normalize=True)

df.groupby(df["review_date"].dt.to_period("M"))["Score"].mean()

product_stats = df.groupby("ProductId").agg(
 avg_rating=("Score", "mean"),
 review_count=("Score", "count"))
product_stats[
 (product_stats["avg_rating"] < 3.5) &
(product_stats["review_count"] > product_stats["review_count"].quantile(0.75))]

from textblob import TextBlob

def get_sentiment_score(text):
 return TextBlob(text).sentiment.polarity

df["sentiment_score"] = df["Text;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;"].apply(get_sentiment_score)

df

def get_sentiment_label(score):
    if score > 0.1:
        return "Positive"
    elif score < -0.1:
        return "Negative"
    else:
        return "Neutral"
df["sentiment_label"] = df["sentiment_score"].apply(get_sentiment_label)

pd.crosstab(df["Score"], df["sentiment_label"], normalize="index")

product_sentiment = df.groupby("ProductId")["sentiment_label"].value_counts(normalize=True).unstack()
product_sentiment.head()

ys = 'I really hate this shit, waste of money!'

blob = TextBlob(ys)

polarity = blob.sentiment.polarity
subjectivity = blob.sentiment.subjectivity

print("text",ys)
print("polarity score",polarity)
print("sub score", subjectivity)

df

df.to_csv('Amazon_Reviews_with_Sentiment.csv', index=False)
print('DataFrame saved to Amazon_Reviews_with_Sentiment.csv')

# You can also download the file directly from Colab's file system by clicking the folder icon on the left panel.